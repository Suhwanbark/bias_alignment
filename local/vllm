#!/bin/bash
# ══════════════════════════════════════════════════════════════
# vLLM Server Launcher
# ══════════════════════════════════════════════════════════════
#
# 사용법:
#   ./vllm                  # 기본 모델(qwen) 실행
#   ./vllm qwen             # Qwen3-30B 실행
#   ./vllm glm              # GLM-4.7-Flash 실행
#   ./vllm nemotron         # Nemotron-3-Nano-30B 실행
#   ./vllm stop             # 서버 종료
#   ./vllm status           # 서버 상태 확인
#   ./vllm list             # 사용 가능한 모델 목록
#
# ══════════════════════════════════════════════════════════════

TENSOR_PARALLEL=4
PORT=8000
MAX_MODEL_LEN=4096

# 모델 선택
select_model() {
    case "$1" in
        qwen|Qwen|QWEN|"")
            echo "Qwen/Qwen3-30B-A3B-Instruct-2507"
            ;;
        glm|GLM|glm4)
            echo "zai-org/GLM-4.7-Flash"
            ;;
        nemotron|Nemotron|NEMOTRON|nvidia)
            echo "nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16"
            ;;
        *)
            echo ""
            ;;
    esac
}

case "$1" in
    stop)
        echo "Stopping vLLM server..."
        pkill -f "vllm serve"
        echo "Done"
        ;;
    status)
        if curl -s http://localhost:$PORT/health > /dev/null 2>&1; then
            echo "vLLM server is running on port $PORT"
            curl -s http://localhost:$PORT/v1/models | python -c "import sys,json; d=json.load(sys.stdin); print(f'Model: {d[\"data\"][0][\"id\"]}')" 2>/dev/null
        else
            echo "vLLM server is not running"
        fi
        ;;
    list)
        echo "사용 가능한 모델:"
        echo "  qwen      - Qwen/Qwen3-30B-A3B-Instruct-2507"
        echo "  glm       - zai-org/GLM-4.7-Flash"
        echo "  nemotron  - nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16"
        echo ""
        echo "사용법: ./vllm [모델명]"
        echo "예시:   ./vllm glm"
        ;;
    *)
        MODEL_ID=$(select_model "$1")
        if [ -z "$MODEL_ID" ]; then
            echo "알 수 없는 모델: $1"
            echo "./vllm list 로 사용 가능한 모델을 확인하세요."
            exit 1
        fi

        echo "Starting vLLM server..."
        echo "Model: $MODEL_ID"
        echo "Tensor Parallel: $TENSOR_PARALLEL"
        echo "Port: $PORT"
        echo ""
        vllm serve $MODEL_ID \
            --tensor-parallel-size $TENSOR_PARALLEL \
            --port $PORT \
            --max-model-len $MAX_MODEL_LEN \
            --trust-remote-code
        ;;
esac
